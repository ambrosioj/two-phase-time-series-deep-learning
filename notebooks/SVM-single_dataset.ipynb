{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bash_command(command):\n",
    "    try:\n",
    "        output = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT)\n",
    "        print(\"Output:\", output.decode('utf-8'))\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error:\", e.output.decode('utf-8'))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateSVM(object):\n",
    "\n",
    "  SOURCEPATH = '..'\n",
    "  OFFSET = 1e-64\n",
    "  MAXITER = 1000\n",
    "  RANDOMSTATE = 42\n",
    "\n",
    "  KERNEL = 'poly'\n",
    "  GAMMA = 10\n",
    "  DEGREE = 3\n",
    "  COEF0 = 10\n",
    "  C = 1\n",
    "\n",
    "\n",
    "  def __init__(self, method, dataset):\n",
    "    self.features = None\n",
    "    self.labels = None\n",
    "    self.train_indices = []\n",
    "    self.test_indices = []\n",
    "    self.model = None\n",
    "    self.method = method\n",
    "    self.dataset = dataset\n",
    "\n",
    "  def load_features(self):\n",
    "    features_path = f\"{self.SOURCEPATH}/data/gmm/{self.dataset.replace('.npy','')}\"\n",
    "    self.features = np.load(f'{features_path}/input_features.npy')\n",
    "    self.labels = np.load(f'{features_path}/labels.npy')\n",
    "    print('\"get_features\" function - features and labels read with success')\n",
    "    print('\\n')\n",
    "\n",
    "  def partition_data(self):\n",
    "    # Initialize the StratifiedShuffleSplit object\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Get the train and test indices for the split\n",
    "    train_index, test_index = next(sss.split(self.features, self.labels))\n",
    "\n",
    "    # Assign the splits to the respective variables\n",
    "    self.X_train, self.X_test = self.features[train_index], self.features[test_index]\n",
    "    self.y_train, self.y_test = self.labels[train_index], self.labels[test_index]\n",
    "\n",
    "  def load_model(self):\n",
    "\n",
    "    try:\n",
    "      model_path = f\"{self.SOURCEPATH}/models/single_dataset/{self.dataset.replace('.npy','')}/svm\"\n",
    "      self.model = joblib.load(f'{model_path}/svm_model.pkl')\n",
    "      print(f'Model loaded from {model_path}')\n",
    "    except:\n",
    "      print(\"Model Not Found!\")\n",
    "      print('Training Model!')\n",
    "      self.train_model()\n",
    "\n",
    "  def train_model(self):\n",
    "    # Train the SVM model\n",
    "    self.model = SVC(\n",
    "        kernel=self.KERNEL,\n",
    "        C=self.C,\n",
    "        gamma=self.GAMMA,\n",
    "        degree=self.DEGREE,\n",
    "        coef0=self.COEF0\n",
    "    )\n",
    "    self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = f\"{self.SOURCEPATH}/models/single_dataset/{self.dataset.replace('.npy','')}/svm\"\n",
    "    try:\n",
    "        run_bash_command(f\"mkdir -p {model_path}\")\n",
    "    except:\n",
    "        print(\"Folder already exists!\")\n",
    "\n",
    "    print(f\"Saving model on {model_path}\")\n",
    "    joblib.dump(self.model, f'{model_path}/svm_model.pkl')\n",
    "\n",
    "  def calc_metrics(self, metrics_features, metrics_labels):\n",
    "     # Predict the training labels\n",
    "    predictions = self.model.predict(metrics_features)\n",
    "\n",
    "    # Calculate and display metrics\n",
    "    accuracy = accuracy_score(metrics_labels, predictions)\n",
    "    precision = precision_score(metrics_labels, predictions, average=self.method)\n",
    "    recall = recall_score(metrics_labels, predictions, average=self.method)\n",
    "    f1 = f1_score(metrics_labels, predictions, average=self.method)\n",
    "    balanced_accuracy = balanced_accuracy_score(metrics_labels, predictions)\n",
    "\n",
    "    metrics_dict = {\"Accuracy\":accuracy,\n",
    "                 \"Precision\":precision,\n",
    "                 \"Recall\":recall,\n",
    "                 \"F1-Score\":f1,\n",
    "                 \"Balanced Accuracy\":balanced_accuracy\n",
    "                 }\n",
    "    # Compute and plot the confusion matrix\n",
    "    cm = confusion_matrix(metrics_labels, predictions)\n",
    "\n",
    "    return metrics_dict, cm\n",
    "\n",
    "  def save_metrics(self):\n",
    "    train_metrics, train_cm = self.calc_metrics(self.X_train, self.y_train)\n",
    "    test_metrics, test_cm = self.calc_metrics(self.X_test, self.y_test)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=train_cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix for Training Phase\")\n",
    "    plt.show()\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=test_cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix for Testing Phase\")\n",
    "    plt.show()\n",
    "\n",
    "    print(train_metrics)\n",
    "\n",
    "    print(test_metrics)\n",
    "\n",
    "    metrics_path = f\"{self.SOURCEPATH}/metrics/single_dataset/{self.dataset.replace('.npy','')}\"\n",
    "\n",
    "    try:\n",
    "      run_bash_command(f\"mkdir -p {metrics_path}\")\n",
    "    except:\n",
    "      print(\"Folder already exist!\")\n",
    "\n",
    "    np.save(f\"{metrics_path}/svm_train_cm.npy\", train_cm)\n",
    "    np.save(f\"{metrics_path}/svm_X_train.npy\", self.X_train)\n",
    "    np.save(f\"{metrics_path}/svm_test_cm.npy\", test_cm)\n",
    "    np.save(f\"{metrics_path}/svm_X_test.npy\", self.X_test)\n",
    "    np.save(f\"{metrics_path}/svm_y_train.npy\", self.y_train)\n",
    "    np.save(f\"{metrics_path}/svm_y_test.npy\", self.y_test)\n",
    "\n",
    "    with open(f\"{metrics_path}/svm_metrics_train.json\", \"w\") as outfile:\n",
    "        json.dump(train_metrics, outfile, indent=4)\n",
    "\n",
    "    with open(f\"{metrics_path}/svm_metrics_test.json\", \"w\") as outfile:\n",
    "        json.dump(test_metrics, outfile, indent=4)\n",
    "\n",
    "  def evaluate_model(self):\n",
    "    self.load_features()\n",
    "    self.partition_data()\n",
    "    self.load_model()\n",
    "    self.save_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method='weighted'\n",
    "dataset = 'window_4000_overlap_1000_hzdr_norm.npy'\n",
    "\n",
    "EVAL = EvaluateSVM(method, dataset)\n",
    "EVAL.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'window_4000_overlap_1000_tud_norm.npy'\n",
    "\n",
    "EVAL = EvaluateSVM(method, dataset)\n",
    "EVAL.evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieee-article-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

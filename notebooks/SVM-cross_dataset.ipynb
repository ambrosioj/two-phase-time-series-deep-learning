{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bash_command(command):\n",
    "    try:\n",
    "        output = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT)\n",
    "        print(\"Output:\", output.decode('utf-8'))\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error:\", e.output.decode('utf-8'))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateSVM(object):\n",
    "\n",
    "  SOURCEPATH = '..'\n",
    "  OFFSET = 1e-64\n",
    "  MAXITER = 1000\n",
    "  RANDOMSTATE = 42\n",
    "\n",
    "  KERNEL = 'poly'\n",
    "  GAMMA = 10\n",
    "  DEGREE = 3\n",
    "  COEF0 = 10\n",
    "  C = 1\n",
    "\n",
    "  def __init__(self, method, train_dataset, test_dataset):\n",
    "    self.train_dataset = train_dataset\n",
    "    self.test_dataset = test_dataset\n",
    "    self.X_train = None\n",
    "    self.X_test = None\n",
    "    self.y_train = None\n",
    "    self.y_test = None\n",
    "    self.model = None\n",
    "    self.method = method\n",
    "\n",
    "  def load_features(self, dataset):\n",
    "    features_path = f\"{self.SOURCEPATH}/data/gmm/{dataset.replace('.npy','')}\"\n",
    "    features = np.load(f'{features_path}/input_features.npy')\n",
    "    labels = np.load(f'{features_path}/labels.npy')\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "  def load_data(self):\n",
    "    self.X_train, self.y_train = self.load_features(self.train_dataset)\n",
    "    self.X_test, self.y_test = self.load_features(self.test_dataset)\n",
    "\n",
    "    print(f\"X_train shape: {self.X_train.shape}\")\n",
    "    print(f\"y_train shape: {self.y_train.shape}\")\n",
    "\n",
    "    print(f\"X_test shape: {self.X_test.shape}\")\n",
    "    print(f\"y_test shape: {self.y_test.shape}\")\n",
    "\n",
    "\n",
    "  def load_model(self):\n",
    "\n",
    "    try:\n",
    "      model_path = f\"{self.SOURCEPATH}/models/cross_dataset/{self.train_dataset.replace('.npy','')}/svm\"\n",
    "      self.model = joblib.load(f'{model_path}/svm_model.pkl')\n",
    "      print(f'Model loaded from {model_path}')\n",
    "    except:\n",
    "      print(\"Model Not Found!\")\n",
    "      print('Training Model!')\n",
    "      self.train_model()\n",
    "\n",
    "  def train_model(self):\n",
    "    # Train the SVM model\n",
    "    self.model = SVC(\n",
    "        kernel=self.KERNEL,\n",
    "        C=self.C,\n",
    "        gamma=self.GAMMA\n",
    "    )\n",
    "    self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = f\"{self.SOURCEPATH}/models/cross_dataset/{self.train_dataset.replace('.npy','')}/svm\"\n",
    "    try:\n",
    "        run_bash_command(f\"mkdir -p {model_path}\")\n",
    "    except:\n",
    "        print(\"Folder already exists!\")\n",
    "\n",
    "    print(f\"Saving model on {model_path}\")\n",
    "    joblib.dump(self.model, f'{model_path}/svm_model.pkl')\n",
    "\n",
    "  def calc_metrics(self, metrics_features, metrics_labels):\n",
    "     # Predict the training labels\n",
    "    predictions = self.model.predict(metrics_features)\n",
    "\n",
    "    # Calculate and display metrics\n",
    "    accuracy = accuracy_score(metrics_labels, predictions)\n",
    "    precision = precision_score(metrics_labels, predictions, average=self.method)\n",
    "    recall = recall_score(metrics_labels, predictions, average=self.method)\n",
    "    f1 = f1_score(metrics_labels, predictions, average=self.method)\n",
    "    balanced_accuracy = balanced_accuracy_score(metrics_labels, predictions)\n",
    "\n",
    "    metrics_dict = {\"Accuracy\":accuracy,\n",
    "                 \"Precision\":precision,\n",
    "                 \"Recall\":recall,\n",
    "                 \"F1-Score\":f1,\n",
    "                 \"Balanced Accuracy\":balanced_accuracy\n",
    "                 }\n",
    "    # Compute and plot the confusion matrix\n",
    "    cm = confusion_matrix(metrics_labels, predictions)\n",
    "\n",
    "    return metrics_dict, cm\n",
    "\n",
    "  def save_metrics(self):\n",
    "    train_metrics, train_cm = self.calc_metrics(self.X_train, self.y_train)\n",
    "    test_metrics, test_cm = self.calc_metrics(self.X_test, self.y_test)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=train_cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix for Training Phase\")\n",
    "    plt.show()\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=test_cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix for Testing Phase\")\n",
    "    plt.show()\n",
    "\n",
    "    print(train_metrics)\n",
    "\n",
    "    print(test_metrics)\n",
    "\n",
    "    metrics_path = f\"{self.SOURCEPATH}/metrics/cross_dataset/{self.train_dataset.replace('.npy','')}\"\n",
    "\n",
    "    try:\n",
    "      run_bash_command(f\"mkdir -p {metrics_path}\")\n",
    "    except:\n",
    "      print(\"Folder already exist!\")\n",
    "\n",
    "    np.save(f\"{metrics_path}/svm_train_cm.npy\", train_cm)\n",
    "    np.save(f\"{metrics_path}/svm_test_cm.npy\", test_cm)\n",
    "\n",
    "    with open(f\"{metrics_path}/svm_metrics_train.json\", \"w\") as outfile:\n",
    "        json.dump(train_metrics, outfile, indent=4)\n",
    "\n",
    "    with open(f\"{metrics_path}/svm_metrics_test.json\", \"w\") as outfile:\n",
    "        json.dump(test_metrics, outfile, indent=4)\n",
    "\n",
    "  def evaluate_model(self):\n",
    "    self.load_data()\n",
    "    self.load_model()\n",
    "    self.save_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method='weighted'\n",
    "\n",
    "train_dataset = 'window_4000_overlap_1000_hzdr_norm.npy'\n",
    "test_dataset = 'window_4000_overlap_1000_tud_norm.npy'\n",
    "\n",
    "EVAL = EvaluateSVM(method, train_dataset, test_dataset)\n",
    "EVAL.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = 'window_4000_overlap_1000_tud_norm.npy'\n",
    "test_dataset = 'window_4000_overlap_1000_hzdr_norm.npy'\n",
    "\n",
    "\n",
    "EVAL = EvaluateSVM(method, train_dataset, test_dataset)\n",
    "EVAL.evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieee-article-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

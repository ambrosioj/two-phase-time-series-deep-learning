{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_bash_command(command):\n",
    "    try:\n",
    "        output = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT)\n",
    "        print(\"Output:\", output.decode('utf-8'))\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error:\", e.output.decode('utf-8'))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateTsai(object):\n",
    "  N_EPOCHS=100\n",
    "  LR=1e-3\n",
    "  SOURCEPATH = '..'\n",
    "\n",
    "  def __init__(self, method, train_dataset, test_dataset):\n",
    "    self.X_train = None\n",
    "    self.X_test = None\n",
    "    self.y_train = None\n",
    "    self.y_test = None\n",
    "    self.learn = None\n",
    "    self.dls = None\n",
    "    self.method = method\n",
    "    self.train_dataset = train_dataset\n",
    "    self.test_dataset = test_dataset\n",
    "\n",
    "  def split_data(self, dataset):\n",
    "    data = np.load(f'{self.SOURCEPATH}/data/{dataset}')\n",
    "    y = data[:,-3:]\n",
    "    labels = np.argmax(y, axis=1) + 1\n",
    "    X = data[:,:-3]\n",
    "    features = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "  def load_data(self):\n",
    "    self.X_train, self.y_train = self.split_data(self.train_dataset)\n",
    "    self.X_test, self.y_test = self.split_data(self.test_dataset)\n",
    "\n",
    "    print(f\"X_train shape: {self.X_train.shape}\")\n",
    "    print(f\"y_train shape: {self.y_train.shape}\")\n",
    "\n",
    "    print(f\"X_test shape: {self.X_test.shape}\")\n",
    "    print(f\"y_test shape: {self.y_test.shape}\")\n",
    "\n",
    "\n",
    "  def train_model(self, architecture, alias, parameters):\n",
    "    # Parameters\n",
    "    bs=[64, 128]\n",
    "\n",
    "    # Create time series\n",
    "    splits=get_splits(\n",
    "        self.y_train,\n",
    "        valid_size=.3,\n",
    "        stratify=True,\n",
    "        random_state=42,\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "    tfms=[None,[Categorize()]]\n",
    "    dsets=TSDatasets(\n",
    "        self.X_train,\n",
    "        self.y_train,\n",
    "        tfms=tfms,\n",
    "        splits=splits,\n",
    "        inplace=True\n",
    "        )\n",
    "\n",
    "    dls=TSDataLoaders.from_dsets(\n",
    "        dsets.train,\n",
    "        dsets.valid,\n",
    "        bs=bs,\n",
    "        batch_tfms=[TSStandardize()]\n",
    "        )\n",
    "\n",
    "    model = create_model(architecture, dls=dls, **parameters)\n",
    "\n",
    "    learn = Learner(dls,\n",
    "                    model,\n",
    "                    metrics=accuracy)\n",
    "    start = time.time()\n",
    "    learn.fit_one_cycle(self.N_EPOCHS,\n",
    "                        lr_max=self.LR)\n",
    "    print(f'Training model: {alias}')\n",
    "    print('\\nElapsed time:', time.time() - start)\n",
    "\n",
    "    self.learn=learn\n",
    "    self.dls=dls\n",
    "\n",
    "  def load_model(self, architecture, parameters, alias):\n",
    "    model_path = f\"\"\"{self.SOURCEPATH}/models/cross_dataset/{self.train_dataset.replace('.npy','')}/{alias}_{parameters}\"\"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        self.model = load_learner_all(path=model_path,\n",
    "                                      dls_fname='dls',\n",
    "                                      model_fname='model',\n",
    "                                      learner_fname='learner')\n",
    "        print(f\"Model found: {model_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model not found!\")\n",
    "        print(\"Training a new model!\")\n",
    "\n",
    "        splits = get_splits(self.y_train,\n",
    "                            valid_size=.3,\n",
    "                            stratify=True,\n",
    "                            random_state=42,\n",
    "                            shuffle=True)\n",
    "\n",
    "        tfms = [None, TSClassification()]\n",
    "        batch_tfms = TSStandardize(by_sample=True)\n",
    "        self.model = TSClassifier(self.X_train, self.y_train, splits=splits,\n",
    "                                  arch=architecture, tfms=tfms, arch_config=parameters,\n",
    "                                  batch_tfms=batch_tfms, metrics=accuracy, cbs=ShowGraph())\n",
    "        self.model.fit_one_cycle(self.N_EPOCHS, lr_max=self.LR)\n",
    "\n",
    "        try:\n",
    "            run_bash_command(f\"mkdir -p {model_path}\")\n",
    "        except:\n",
    "            print(\"Folder already exists!\")\n",
    "\n",
    "        self.model.save_all(path=model_path,\n",
    "                            dls_fname='dls',\n",
    "                            model_fname='model',\n",
    "                            learner_fname='learner')\n",
    "\n",
    "        print(f\"Model saved as: {model_path}\")\n",
    "\n",
    "  def get_metrics(self, architecture, alias, parameters, write_flag=False):\n",
    "\n",
    "    test_probas, test_targets, test_preds = self.model.get_X_preds(\n",
    "        self.X_test, self.y_test)\n",
    "\n",
    "    accuracy = accuracy_score(self.y_test.astype(str), test_preds.astype(str))\n",
    "    precision = precision_score(self.y_test.astype(str), test_preds.astype(str), average=self.method)\n",
    "    recall = recall_score(self.y_test.astype(str), test_preds.astype(str), average=self.method)\n",
    "    f1 = f1_score(self.y_test.astype(str), test_preds.astype(str), average=self.method)\n",
    "    balanced_accuracy = balanced_accuracy_score(self.y_test.astype(str), test_preds.astype(str))\n",
    "\n",
    "    iter_dict = {\"Accuracy\":accuracy,\n",
    "                 \"Precision\":precision,\n",
    "                 \"Recall\":recall,\n",
    "                 \"F1-Score\":f1,\n",
    "                 \"Balanced Accuracy\":balanced_accuracy,\n",
    "                 'Model':alias,\n",
    "                 'Parameters':parameters}\n",
    "\n",
    "    # Generating the confusion matrix\n",
    "    cm = confusion_matrix(self.y_test.astype(str), test_preds.astype(str))\n",
    "\n",
    "    self.model.plot_confusion_matrix()\n",
    "\n",
    "    # Optional: Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "\n",
    "    metrics_path = f\"\"\"{self.SOURCEPATH}/metrics/cross_dataset/{self.train_dataset.replace('.npy','')}\"\"\"\n",
    "\n",
    "    print(iter_dict)\n",
    "\n",
    "    if write_flag:\n",
    "      try:\n",
    "        run_bash_command(f\"mkdir -p {metrics_path}\")\n",
    "      except:\n",
    "        print(\"Folder already exist!\")\n",
    "\n",
    "      with open(f\"{metrics_path}/{alias}_{parameters}.json\", \"w\") as outfile:\n",
    "        json.dump(iter_dict, outfile, indent=4)\n",
    "\n",
    "        np.save(f\"{metrics_path}/{alias}_{parameters}_cm.npy\", cm)\n",
    "\n",
    "\n",
    "      print(f\"Metrics saved as: {metrics_path}/{alias}_{parameters}.json\")\n",
    "\n",
    "  def evaluate_model(self, archs, write_flag):\n",
    "    self.load_data()\n",
    "\n",
    "    for (architecture, parameters, alias) in archs:\n",
    "      self.load_model(architecture, parameters, alias)\n",
    "      self.get_metrics(architecture, parameters, alias, write_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'weighted'\n",
    "train_dataset = 'window_4000_overlap_1000_hzdr_norm.npy'\n",
    "test_dataset = 'window_4000_overlap_1000_tud_norm.npy'\n",
    "\n",
    "model_definitions = [(ResNet, {}, 'ResNet'),\n",
    "                     (LSTM_FCN, {}, 'LSTM-FCN'),\n",
    "                     (TSTPlus, {},'TSTPlus')]\n",
    "\n",
    "EVAL = EvaluateTsai(method, train_dataset, test_dataset)\n",
    "EVAL.evaluate_model(model_definitions, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = 'window_4000_overlap_1000_tud_norm.npy'\n",
    "test_dataset = 'window_4000_overlap_1000_hzdr_norm.npy'\n",
    "\n",
    "model_definitions = [(ResNet, {}, 'ResNet'),\n",
    "                     (LSTM_FCN, {}, 'LSTM-FCN'),\n",
    "                     (TSTPlus, {},'TSTPlus')]\n",
    "\n",
    "EVAL = EvaluateTsai(method, train_dataset, test_dataset)\n",
    "EVAL.evaluate_model(model_definitions, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieee-article-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
